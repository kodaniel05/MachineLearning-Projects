{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96914071",
   "metadata": {},
   "source": [
    "# Large Language Models (LLMs): Transformers & Mini‑LLM\n",
    "\n",
    "This notebook implements all required parts of the project:\n",
    "\n",
    "- Data helpers (`read_lines`, `clean_text`)\n",
    "- **Q1:** `build_vocab`, `generate_dataset`\n",
    "- **Q2:** `positional_encoding`\n",
    "- **Q3:** `MultiHeadAttention`\n",
    "- **Q4:** `TransformerBlock`, `MiniLLM`\n",
    "- **Q5:** `train_model`, `generate_text` + a quick demo harness\n",
    "\n",
    "> Dataset path used: `/anvil/projects/tdm/data/amazon/music.txt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Helpers: reading & cleaning ---\n",
    "from typing import List, Tuple, Dict\n",
    "import codecs\n",
    "\n",
    "def read_lines(file_path: str, n: int, start: int = 0) -> List[str]:\n",
    "    lines = []\n",
    "    with open(file_path, 'r') as f:  # open the file in read mode\n",
    "        for i, line in enumerate(f):\n",
    "            if i < start:\n",
    "                continue\n",
    "            lines.append(line.strip())\n",
    "            if len(lines) == n:\n",
    "                break\n",
    "    return lines\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    '''\n",
    "    1) decode escape sequences\n",
    "    2) replace any newlines with a space\n",
    "    3) lowercase\n",
    "    4) keep only alphabetic + whitespace\n",
    "    '''\n",
    "    text = codecs.decode(text, 'unicode_escape')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.lower()\n",
    "    text = ''.join(c for c in text if c.isalpha() or c.isspace())\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6d5e38",
   "metadata": {},
   "source": [
    "## Q1 — Vocabulary & Dataset Builders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7878cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "\n",
    "def build_vocab(lines: List[str]) -> Tuple[Dict[str, int], List[str]]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      token_to_idx: dict mapping token -> index\n",
    "      idx_to_token: list such that idx_to_token[i] gives token for index i\n",
    "    \"\"\"\n",
    "    token_to_idx: Dict[str, int] = {}\n",
    "    idx_to_token: List[str] = []\n",
    "    for line in lines:\n",
    "        for token in clean_text(line).split():\n",
    "            if token not in token_to_idx:\n",
    "                token_to_idx[token] = len(idx_to_token)\n",
    "                idx_to_token.append(token)\n",
    "    return token_to_idx, idx_to_token\n",
    "\n",
    "def generate_dataset(lines: List[str], token_to_idx: Dict[str, int], sequence_length: int):\n",
    "    \"\"\"\n",
    "    For each review:\n",
    "      - clean + split\n",
    "      - skip if not long enough\n",
    "      - convert tokens -> indices\n",
    "      - create sliding window of length `sequence_length` as inputs and next token as output\n",
    "    Returns: (inputs, outputs) where both are Python lists of sequences/targets (ints).\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for line in lines:\n",
    "        split_text = clean_text(line).split()\n",
    "        if len(split_text) < sequence_length + 1:\n",
    "            continue\n",
    "        tokens = [token_to_idx[w] for w in split_text if w in token_to_idx]\n",
    "        if len(tokens) < sequence_length + 1:\n",
    "            continue\n",
    "        for i in range(len(tokens) - sequence_length):\n",
    "            x = tokens[i:i+sequence_length]\n",
    "            y = tokens[i+sequence_length]\n",
    "            inputs.append(x)\n",
    "            outputs.append(y)\n",
    "    return inputs, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Q1 quick test ---\n",
    "try:\n",
    "    sequence_len = 3\n",
    "    lines = read_lines('/anvil/projects/tdm/data/amazon/music.txt', 500)\n",
    "    token_to_idx, idx_to_token = build_vocab(lines)\n",
    "    inputs, outputs = generate_dataset(lines, token_to_idx, sequence_len)\n",
    "    print(f'Length of Inputs {len(inputs)}')  # Expected ~11095\n",
    "    print(f\"CD Index: {token_to_idx.get('cd', None)}\")  # Expected 3 in the prompt\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found in this environment. Update the path if needed and re-run this cell.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9fab8e",
   "metadata": {},
   "source": [
    "## Q2 — Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ce451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch, math\n",
    "\n",
    "def positional_encoding(seq_len: int, model_dimensions: int) -> torch.Tensor:\n",
    "    \"\"\"Returns tensor of shape [1, seq_len, model_dimensions] with sinusoidal PE.\"\"\"\n",
    "    pe = torch.zeros(seq_len, model_dimensions, dtype=torch.float32)  # [T, C]\n",
    "    position = torch.arange(0, seq_len, dtype=torch.float32).unsqueeze(1)  # [T, 1]\n",
    "    div_term = torch.exp(-math.log(10000.0) * (torch.arange(0, model_dimensions, 2, dtype=torch.float32) / model_dimensions))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)  # even\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)  # odd\n",
    "    return pe.unsqueeze(0)  # [1, T, C]\n",
    "\n",
    "# Sanity check from prompt\n",
    "pe = positional_encoding(10, 4)\n",
    "print(pe.shape)                       # torch.Size([1, 10, 4])\n",
    "print(torch.round(pe[0, 0, :], decimals=4))\n",
    "print(torch.round(pe[0, 1, :], decimals=4))\n",
    "print(torch.round(pe[0, 2, :], decimals=4))\n",
    "print(torch.round(pe[0, 3, :], decimals=4))\n",
    "print(torch.round(pe[0, 4, :], decimals=4))\n",
    "print(torch.round(pe[0, 5, :], decimals=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774fabcc",
   "metadata": {},
   "source": [
    "## Q3 — Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, model_dimensions: int, num_heads: int):\n",
    "        super().__init__()\n",
    "        assert model_dimensions % num_heads == 0, \"model_dimensions must be divisible by num_heads\"\n",
    "        self.d_k = model_dimensions // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.qkv = torch.nn.Linear(model_dimensions, model_dimensions * 3)\n",
    "        self.fc_out = torch.nn.Linear(model_dimensions, model_dimensions)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [B, T, C]\n",
    "        B, T, C = x.size()\n",
    "        qkv = self.qkv(x).reshape(B, T, 3, self.num_heads, self.d_k).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]   # each: [B, H, T, d_k]\n",
    "        scores = (q @ k.transpose(-2, -1)) / math.sqrt(self.d_k)  # [B, H, T, T]\n",
    "        attn = torch.softmax(scores, dim=-1)                      # [B, H, T, T]\n",
    "        out = (attn @ v).transpose(1, 2).reshape(B, T, C)         # [B, T, C]\n",
    "        return self.fc_out(out)                                   # [B, T, C]\n",
    "\n",
    "# Sanity check\n",
    "import numpy as np, random\n",
    "b, t, c, h = 2, 5, 128, 4\n",
    "mha = MultiHeadAttention(c, h)\n",
    "torch.manual_seed(78); np.random.seed(78); random.seed(78)\n",
    "x = torch.from_numpy(np.random.rand(b, t, c).astype('f'))\n",
    "y = mha(x)\n",
    "print(y.shape)\n",
    "print(y[0][0][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b2b9e1",
   "metadata": {},
   "source": [
    "## Q4 — Transformer Block & Mini‑LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a210306",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerBlock(torch.nn.Module):\n",
    "    def __init__(self, model_dimensions: int, num_heads: int, attention_class=MultiHeadAttention):\n",
    "        super().__init__()\n",
    "        self.attn = attention_class(model_dimensions, num_heads)\n",
    "        self.norm1 = torch.nn.LayerNorm(model_dimensions)\n",
    "        self.ff = torch.nn.Sequential(\n",
    "            torch.nn.Linear(model_dimensions, 4 * model_dimensions),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(4 * model_dimensions, model_dimensions)\n",
    "        )\n",
    "        self.norm2 = torch.nn.LayerNorm(model_dimensions)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x + self.attn(x)\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.ff(x)\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "class MiniLLM(torch.nn.Module):\n",
    "    def __init__(self, vocab_size: int, model_dimensions: int = 128, num_heads: int = 4, num_layers: int = 2, seq_len: int = 10, attention_class=MultiHeadAttention):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(vocab_size, model_dimensions)\n",
    "        self.register_buffer('pe', positional_encoding(seq_len, model_dimensions))\n",
    "        blocks = [TransformerBlock(model_dimensions, num_heads, attention_class=attention_class) for _ in range(num_layers)]\n",
    "        self.transformer_blocks = torch.nn.Sequential(*blocks)\n",
    "        self.fc = torch.nn.Linear(model_dimensions, vocab_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        positional_encodings = self.pe[:, :x.size(1), :]\n",
    "        x = self.embed(x) + positional_encodings\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f37cd25",
   "metadata": {},
   "source": [
    "## Q5 — Training Loop & Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_model(model: torch.nn.Module, inputs, targets, epochs: int = 5, learning_rate: float = 1e-3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), desc='Training Epochs'):\n",
    "        total_loss = 0.0\n",
    "        for i, (x, y) in tqdm(enumerate(zip(inputs, targets)), desc=f'Epoch {epoch+1}', total=len(inputs), leave=False):\n",
    "            x_tensor = torch.tensor([x], dtype=torch.long)         # [B=1, T]\n",
    "            y_tensor = torch.tensor([y], dtype=torch.long)         # [B=1]\n",
    "            logits = model(x_tensor)                                # [1, V]\n",
    "            loss = loss_fn(logits, y_tensor)                        # CE expects [N, C] and target [N]\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg = total_loss / max(1, len(inputs))\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg:.4f}\")\n",
    "    return model\n",
    "\n",
    "def generate_text(model, start_sequence: str, token_to_idx, idx_to_token, length: int = 20, context_length: int = 10, temperature: float = 1.0):\n",
    "    model.eval()\n",
    "    current = [token_to_idx.get(tok, None) for tok in start_sequence.split()]\n",
    "    current = [i for i in current if i is not None]\n",
    "    if not current:\n",
    "        return \"\"\n",
    "    for _ in range(length):\n",
    "        x = torch.tensor([current[-context_length:]], dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)  # [1, V]\n",
    "            probs = F.softmax(logits / max(1e-6, temperature), dim=-1).squeeze(0)  # [V]\n",
    "            next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "            current.append(next_token)\n",
    "    return ' '.join(idx_to_token[i] for i in current)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4c15c",
   "metadata": {},
   "source": [
    "### Quick Smoke Test (tiny subset for speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b98477",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tiny demo to verify end-to-end flow quickly.\n",
    "try:\n",
    "    CONTEXT = 6\n",
    "    LINES = read_lines('/anvil/projects/tdm/data/amazon/music.txt', 300)\n",
    "    tok2i, i2tok = build_vocab(LINES)\n",
    "    X, Y = generate_dataset(LINES, tok2i, CONTEXT)\n",
    "    vocab_size = len(tok2i)\n",
    "    model = MiniLLM(vocab_size, model_dimensions=64, num_heads=4, num_layers=2, seq_len=CONTEXT)\n",
    "    train_model(model, X[:2000], Y[:2000], epochs=2, learning_rate=1e-3)\n",
    "    prompt = \"this cd is the\"\n",
    "    out = generate_text(model, prompt, tok2i, i2tok, length=12, context_length=CONTEXT, temperature=0.9)\n",
    "    print(\"Prompt:\", prompt)\n",
    "    print(\"Output:\", out)\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found in this environment. Update the path and re-run.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
